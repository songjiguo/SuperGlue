/**
 * Copyright 2008 by Boston University.  All rights reserved.
 * Copyright 2011 by The George Washington University.  All rights reserved.
 *
 * Redistribution of this file is permitted under the GNU General
 * Public License v2.
 *
 * Author: Gabriel Parmer, gabep1@cs.bu.edu, 2008.
 * Author: Gabriel Parmer, gparmer@gwu.edu, 2011.
 * Author: Gabriel Parmer, gparmer@gwu.edu, 2012: add real groups.
 */

#define COS_FMT_PRINT

#include <cos_synchronization.h>
#include <cos_component.h>
#include <cos_alloc.h>
#include <cos_debug.h>
#include <cos_list.h>
#include <print.h>
#include <cmap.h>
#include <errno.h>
#include <evt.h>
#include <sched.h>

#include <lock.h>

#include <name_server.h>
extern int lock_reflect(spdid_t spdid);

#include <cvect.h>

static int test_num = 0;

typedef enum {
	EVT_GROUP, 
	EVT_NORMAL
} evt_t;

typedef enum {
	EVT_BLOCKED   = 0x1,    /* a thread is blocked on this event */
	EVT_TRIGGERED = 0x2 	/* has the event been triggered */
} evt_status_t;

struct evt {
	evt_t type;
	evt_status_t status;
	long eid;
	struct evt *grp;
	struct evt *iachildren, *tchildren; /* inactive and triggered children */
	struct evt *next, *prev;
	u16_t bthd;	                    /* blocked thread */
	spdid_t creator;
};

#define CSLAB_ALLOC(sz)   alloc_page()
#define CSLAB_FREE(x, sz) free_page(x)
#include <cslab.h>
CSLAB_CREATE(evt, sizeof(struct evt));
/* A mapping between event ids and actual events */
CVECT_CREATE_STATIC(evt_map);

/* lock name start */
cos_lock_t evt_lock;
/* lock name end */


// Jiguo: need error_code to return different situation (e.g, parent not presented)
static struct evt *
__evt_alloc(evt_t t, long parent, spdid_t spdid, int existing_id, int *error_code)
{
	struct evt *e = NULL, *p = NULL;

	if (parent) {
		p = cvect_lookup(&evt_map, parent);
		if (!p) {
			*error_code = -EINVAL;
			goto done;
		}
		if (p->creator != spdid)  goto done;
		if (p->type != EVT_GROUP) goto done;
	}
	e = cslab_alloc_evt();
	if (!e) goto done;
	memset(e, 0, sizeof(struct evt));

	e->type = t;
	INIT_LIST(e, next, prev);
	e->grp  = p;
	e->creator = spdid;
	if (p) {
		if (p->iachildren) ADD_LIST(p->iachildren, e, next, prev);
		else               p->iachildren = e;
	}

	e->eid = ns_alloc(cos_spd_id(), spdid, existing_id);
	/* when recover, the id might have been deleted and can not be
	 * rebuilt anymore. Return NULL in this case */
	if (e->eid <= 0) return NULL;
	/* assert(e->eid > 0); */
	cvect_add(&evt_map, e, e->eid);
done:
	return e;
}

/* 
 * This does _not_ free all children of a freed group.  They have to
 * be freed individually.
 */
static int
__evt_free(spdid_t spdid, long eid)
{
	struct evt *e, *c, *f;

	e = cvect_lookup(&evt_map, eid);
	if (!e)                  return -EINVAL;
	if (e->creator != spdid) return -EACCES;
	if (e->bthd)             return -EAGAIN;

	if (e->iachildren) {
		f = c = FIRST_LIST(e->iachildren, next, prev);
		do {
			c->grp = NULL;
			REM_LIST(c, next, prev);
		} while (f != (c = FIRST_LIST(e->iachildren, next, prev)));
		e->iachildren = NULL;
	}
	if (e->tchildren) {
		f = c = FIRST_LIST(e->tchildren, next, prev);
		do {
			c->grp = NULL;
			REM_LIST(c, next, prev);
		} while (f != (c = FIRST_LIST(e->tchildren, next, prev)));
		e->tchildren = NULL;
	}
	
	REM_LIST(e, next, prev);
	cvect_del(&evt_map, eid);
	cslab_free_evt(e);

	return 0;
}

/* 
 * Trigger the most specific group with a thread blocked waiting, or
 * the most generic otherwise.
 *
 * Return > 0 for the thread to wake up, 0 for no wakeup, and < 0 for
 * error.
 */
static inline long
__evt_trigger(spdid_t spdid, long eid)
{
	struct evt *e, *g, *t = NULL;

	e = cvect_lookup(&evt_map, eid);

	/* if (unlikely(!e)) {   // changed by Jiguo */
	/* 	/\* Jiguo: evt_trigger can be called from a different */
	/* 	 * spd where the id mappings are not tracked. We call */
	/* 	 * the name server to find the creator and upcall into */
	/* 	 * the creator to recreate the evt */
	/* 	 * If can not see e, it means e has not been recreated */
	/* 	 *\/ */

	/* 	// TODO: remove this to the interface */
	/* 	assert(cos_get_thd_id() != 2); */
	/* 	printc("cant not find evt id %ld by thd %d\n", eid, cos_get_thd_id()); */
	/* 	lock_release(&evt_lock); */
	/* 	ns_upcall(spdid, eid); */
	/* 	lock_take(&evt_lock); */
	/* 	e = cvect_lookup(&evt_map, eid); */
	/* } */
	/* assert(e);	// remove this Jiguo. Then interface should handle this */

	if (!e) {
		printc("can not find event id %d\n", eid);
	} else if(e->type != EVT_NORMAL) 
		printc("event type is wrong\n");

	/* can't trigger groups */
	if (!e || e->type != EVT_NORMAL) return -EINVAL;
	/* go up the tree toward the root... */
	for (g = e ; g ; g = g->grp) {
		g->status |= EVT_TRIGGERED;
		/* add ourselves to the triggered list of our parent,
		 * and propagate the event up. */
		if (g->grp) {
			REM_LIST(g, next, prev);
			/* FIFO event delivery */
			if (!g->grp->tchildren) g->grp->tchildren = g;
			else ADD_END_LIST(g->grp->tchildren, g, next, prev); 
		}
		if (!t && (g->status & EVT_BLOCKED || !g->grp)) t = g;
	}
	assert(t);
	t->status |= EVT_TRIGGERED;
	if (t->status & EVT_BLOCKED) {
		u16_t tid = t->bthd;
		assert(tid);

		t->status &= ~EVT_BLOCKED;
		t->bthd    = 0;
		return tid;
	}
	assert(!t->bthd);
	return 0;
}

/* 
 * Return the event id if one has been triggered, otherwise 0 and the
 * thread should be blocked, only to retry this operation when woken.
 * Negative values denote error values (errno).
 *
 * Note: only one thread can block waiting for a specific event at any
 * time.
 */
static inline long
__evt_wait(spdid_t spdid, long eid)
{
	struct evt *e, *g, *c, *t;

	e = cvect_lookup(&evt_map, eid);
	if (!e)                  return -EINVAL;
	if (e->bthd)             return -EAGAIN; /* another thread already blocked? */
	if (e->creator != spdid) return -EINVAL;   // whey do we need this?  Jiguo
	assert(!(e->status & EVT_BLOCKED));
	assert(e->eid);

	if (!(e->status & EVT_TRIGGERED)) {
		e->status |= EVT_BLOCKED;
		e->bthd = cos_get_thd_id();
		return 0;
	}
	
	if (!e->tchildren) {
		t = e;
	} else { /* find the "bottom" triggered child */
		for (c = e->tchildren ; c->tchildren ; c = c->tchildren) ;
		t = c;
	}
	t->status &= ~EVT_TRIGGERED;
	/* go up from the child, removing "triggered" where appropriate */
	for (g = t->grp ; g ; g = g->grp) {
		struct evt *r, *f;
		int more = 1;
			
		assert(g->tchildren);
		r = g->tchildren;
		if (EMPTY_LIST(r, next, prev)) {
			REM_LIST(r, next, prev);
			g->tchildren = NULL;
			g->status &= ~EVT_TRIGGERED;
		} else {
			f = FIRST_LIST(r, next, prev);
			REM_LIST(r, next, prev);
			g->tchildren = f;
			more = 0;
		}
		if (g->iachildren) ADD_LIST(g->iachildren, r, next, prev);
		else               g->iachildren = r;
		
		if (!more) break;
	}
	return t->eid;
} 

static long 
__evt_split(spdid_t spdid, long parent, int group, int existing_id)
{
	struct evt *e;
	long ret = -ENOMEM;

        /* lock take start */
	lock_take(&evt_lock);
        /* lock take end */
	int error_code = 0;
	e = __evt_alloc(group ? EVT_GROUP : EVT_NORMAL, parent, spdid, 
			existing_id, &error_code);
	if (error_code < 0) ret = error_code;
	if (!e) goto done;
	ret = e->eid;
	assert(ret > 0);

#if (RECOVERY_ENABLE == 1) && defined(TEST_EVT_SPLIT)
	/* printc("test_num %d\n", test_num); */
	if (test_num++ > 1 && cos_get_thd_id() != 2) {
		/* printc("trigger fault in evt_split: thd %d spd %ld passed spd %d\n", cos_get_thd_id(), cos_spd_id(), spdid); */
		assert(0);
	}
#endif

done:
        /* lock release start */
	lock_release(&evt_lock);
        /* lock release end */
	/* printc("evt_split is returning....ret %ld\n", ret); */

	return ret;
}

long evt_split(spdid_t spdid, long parent, int group)
{
	return __evt_split(spdid, parent, group, 0);
}

long 
evt_split_exist(spdid_t spdid, long parent, int group, int existing_id) 
{
	return __evt_split(spdid, parent, group, existing_id);
}

void evt_free(spdid_t spdid, long evt_id)
{
	int ret;

	lock_take(&evt_lock);

#if (RECOVERY_ENABLE == 1) && defined(TEST_EVT_FREE_BEFORE)
	if (test_num++ > 0) {
		/* printc("trigger fault in evt_free before: thd %d spd %ld passed spd %d\n",  */
		/*        cos_get_thd_id(), cos_spd_id(), spdid); */
		assert(0);
	}
#endif

	ret = __evt_free(spdid, evt_id);
	lock_release(&evt_lock);
	
	if (!ret) ns_free(cos_spd_id(), spdid, evt_id);

#if (RECOVERY_ENABLE == 1) && defined(TEST_EVT_FREE_AFTER)
	if (test_num++ > 0) {
		/* printc("trigger fault in evt_free after: thd %d spd %ld passed spd %d\n",  */
		/*        cos_get_thd_id(), cos_spd_id(), spdid); */
		assert(0);
	}
#endif

	return; // ret;
}

long evt_wait_n(spdid_t spdid, long evt_id, int n) {
	assert(0);
	return -1;
}

long evt_wait(spdid_t spdid, long evt_id)
{
	long ret;

#ifdef BENCHMARK_MEAS_INV_OVERHEAD_EVT
	if (cos_get_thd_id() == 13) return 0;
#endif

	do {
		lock_take(&evt_lock);

#if (RECOVERY_ENABLE == 1) && defined(TEST_EVT_WAIT_BEFORE)
		// thd 13 is the testing thread
		if (test_num++ > 20) {
			/* printc("trigger fault in evt_wait before (test_num %d): thd %d spd %ld passed spd %d\n", test_num, cos_get_thd_id(), cos_spd_id(), spdid); */
			assert(0);
		}
#endif

		ret = __evt_wait(spdid, evt_id);
		lock_release(&evt_lock);
		/* printc("thd %d waiting on evt %d\n",cos_get_thd_id(), evt_id); */
		if (!ret && 0 > sched_block(cos_spd_id(), 0)) BUG();

#if (RECOVERY_ENABLE == 1) && defined(TEST_EVT_WAIT_AFTER)
		if (test_num++ > 20) {
			/* printc("trigger fault in evt_wait after (test_num %d): thd %d spd %ld passed spd %d\n", test_num, cos_get_thd_id(), cos_spd_id(), spdid); */
			assert(0);
		}
#endif

	} while (!ret);
	return ret; 
}

int
evt_trigger(spdid_t spdid, long evt_id)
{
	int ret;
	lock_take(&evt_lock);
	printc("thd %d triggers evt %d\n", cos_get_thd_id(), evt_id);


#if (RECOVERY_ENABLE == 1) && defined(TEST_EVT_TRIGGER_BEFORE)
	// thread 14 is the test thread
	if (test_num++ > 20) {
		/* printc("trigger fault in evt_trigger before: thd %d passed spd %d (evt %d)\n", */
		/*        cos_get_thd_id(), spdid, evt_id); */
		assert(0);
	}
#endif

	ret = __evt_trigger(spdid, evt_id);
	lock_release(&evt_lock);

        // change this to return error code
	if (ret > 0 && sched_wakeup(cos_spd_id(), ret)) BUG(); 


#if (RECOVERY_ENABLE == 1) && defined(TEST_EVT_TRIGGER_AFTER)
	if (test_num++ > 20) {
		/* printc("trigger fault in evt_trigger after: thd %d passed spd %d (evt %d)\n", */
		/*        cos_get_thd_id(), spdid, evt_id); */
		assert(0);
	}
#endif

	return ret; // Jiguo: return possible error code
}


static void
rd_reflection()
{
	int count_obj = 0; // reflected objects
	int dest_spd = cos_spd_id();

	lock_take(&evt_lock);  // take the lock to ensure all threads can be woken

	/* // remove the mapped page for evt spd */
	/* vaddr_t addr; */
	/* count_obj = mman_reflect(cos_spd_id(), dest_spd, 1); */
	/* /\* printc("evt relfects on mmgr: %d objs\n", count_obj); *\/ */
	/* while (count_obj--) { */
	/* 	addr = mman_reflect(cos_spd_id(), dest_spd, 0); */
	/* 	/\* printc("evt mman_release: %p addr\n", (void *)addr); *\/ */
	/* 	assert(addr); */
	/* 	memset(addr, 0, PAGE_SIZE);  // zero out anything on this page before release */

	/* 	mman_release_page(cos_spd_id(), addr, dest_spd); */
	/* } */

	
	sched_client_fault_notification(cos_spd_id());

	// to reflect all threads blocked from evt component, such as evt_wait
	/* int wake_thd; */
	/* count_obj =  */
	/* /\* printc("evt relfects on sched: %d objs\n", count_obj); *\/ */
	/* while (count_obj--) { */
	/* 	wake_thd = sched_reflect(cos_spd_id(), dest_spd, 0); */
	/* 	/\* printc("thread %d wake_thd %d\n", cos_get_thd_id(), wake_thd); *\/ */
	/* 	sched_wakeup(cos_spd_id(), wake_thd); */
	/* } */

	/* thread might hold the lock when the server fails. We need
	 * release these locks. Like timed_evt or lock, we could check
	 * the owner of the lock and decide to lock_component_release
	 * during each object recovery. However, take/release API of
	 * lock component do require lock_id explicitly and this lock
	 * id is not known (tracked) on the client interface (evt). So
	 * for now, we still track who have been blocked due to the
	 * lock contention in evt on the lock interface. And call
	 * trigger_all to release that lock during the recovery.
	 
	 Note: maybe we should change the lock component API to not
	 pass lock id, just use the owner thread id to identify the
	 lock meta data structure?
	 */
	lock_client_fault_notification(cos_spd_id());

	lock_release(&evt_lock);
	
	return;
}


void 
cos_init(void)
{
	lock_static_init(&evt_lock);
	cvect_init_static(&evt_map);

	if (unlikely(cos_fault_cntl(COS_CAP_REFLECT_UPDATE, cos_spd_id(), 0))) {
		printc("\nevt reflection start!!!\n");
		rd_reflection();
		printc("evt reflection done!!!\n\n");
	}

}

long
evt_create(spdid_t spdid) { return -1; }

long 
evt_grp_create(spdid_t spdid, long parent) { return -1; }

int 
evt_set_prio(spdid_t spdid, long extern_evt, int prio) { return -1; }

/* Wait on a group of events (like epoll) */
long evt_grp_wait(spdid_t spdid) { return -1; }

/* As above, but return more than one event notifications */
int 
evt_grp_mult_wait(spdid_t spdid, struct cos_array *data) { return -1; }

unsigned long *evt_stats(spdid_t spdid, unsigned long *stats) { return NULL; }
int evt_stats_len(spdid_t spdid) { return 0; }

long __evt_create(spdid_t spdid) {return 0;}

int evt_reflection(spdid_t spdid) {return 0;}
int evt_client_fault_notification(spdid_t spdid) { return 0; }

int evt_upcall_creator(spdid_t spdid, int evtid) 
{
	int ret = 0;
	
	ns_upcall(spdid, evtid, 0);
	
	return ret;
}


