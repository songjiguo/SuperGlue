/**
 * Copyright 2008 by Gabriel Parmer, gabep1@cs.bu.edu.  All rights
 * reserved.
 *
 * Completely rewritten to use a sane data-structure based on the L4
 * mapping data-base -- Gabriel Parmer, gparmer@gwu.edu, 2011.
 *
 * Redistribution of this file is permitted under the GNU General
 * Public License v2.
 *
 * I do _not_ use "embedded mapping nodes" here.  That is, I don't
 * embed the mapping nodes into the per-component "page tables" that
 * are used to look up individual mappings in each component.
 * Additionally, instead of the conventional implementation that has
 * these page table structures point to the frame structure that is
 * the base of the mapping tree, we point directly to the mapping to
 * avoid the O(N) cost when mapping where N is the number of nodes in
 * a mapping tree.  The combination of these design decisions means
 * that we might use more memory and have a few more data cache line
 * accesses.  We use a slab allocator to avoid excessive memory usage
 * for allocating memory mapping structures.  However, we use a very
 * fast (and predictable) lookup structure to perform the (component,
 * address)->mapping lookup.  Unfortunately the memory overhead of
 * that is significant (2 pages per component in the common case).
 * See cvectc.h for an alternative that trades (some) speed for memory
 * usage.
 */

/* 
 * FIXME: locking!
 */

#define COS_FMT_PRINT
#include <cos_component.h>
#include <cos_debug.h>
#include <cos_alloc.h>
#include <print.h>

#include <cos_list.h>
#include "../../sched/cos_sched_ds.h"
#include "../../sched/cos_sched_sync.h"

#if NUM_CPU_COS > 1
#include <ck_spinlock.h>
ck_spinlock_ticket_t xcore_lock = CK_SPINLOCK_TICKET_INITIALIZER;

#define LOCK()   do { if (cos_sched_lock_take())   assert(0); ck_spinlock_ticket_lock_pb(&xcore_lock, 1); } while (0)
#define UNLOCK() do { ck_spinlock_ticket_unlock(&xcore_lock); if (cos_sched_lock_release()) assert(0);    } while (0)
#else
#define LOCK()   if (cos_sched_lock_take())    assert(0);
#define UNLOCK() if (cos_sched_lock_release()) assert(0);
#endif

#include <mem_mgr.h>

#include <recovery_upcall.h>
#if (RECOVERY_ENABLE == 1)
#include <c3_test.h>
#endif
unsigned int swifi_ready = 0;  // explicitly initialize to 0

static int test_control = 0;  // Jiguo: for trigger the fault test

/***************************************************/
/*** Data-structure for tracking physical memory ***/
/***************************************************/

struct mapping;
/* A tagged union, where the tag holds the number of maps: */
struct frame {
	int nmaps;
	union {
		struct mapping *m;  /* nmaps > 0 : root of all mappings */
		vaddr_t addr;	    /* nmaps = -1: local mapping */
		struct frame *free; /* nmaps = 0 : no mapping */
	} c;
} frames[COS_MAX_MEMORY];
struct frame *freelist;

static inline int  frame_index(struct frame *f) { return f-frames; }
static inline int  frame_nrefs(struct frame *f) { return f->nmaps; }
static inline void frame_ref(struct frame *f)   { f->nmaps++; }

static inline struct frame *
frame_alloc(void)
{
	struct frame *f = freelist;

	if (!f) return NULL;
	freelist = f->c.free;
	f->nmaps = 0;
	f->c.m   = NULL;

	return f;
}

static inline struct frame *
frame_alloc_index(int idx)
{
	struct frame *f = NULL;
	if (!freelist) return NULL;

	/* printc("frame_index(freelist) %d  idx %d\n",  */
	/*        frame_index(freelist), idx); */
	assert(frame_index(freelist) <= idx);
	if (frame_index(freelist) == idx) {
		return frame_alloc();
	}
	else {
		frames[idx-1].c.free = &frames[idx+1];
		f = &frames[idx];
		f->nmaps = 0;
		f->c.m   = NULL;
		return f;
	}
}

static inline void
frame_deref(struct frame *f)
{ 
	assert(f->nmaps > 0);
	f->nmaps--; 
	if (f->nmaps == 0) {
		f->c.free = freelist;
		freelist  = f;
	}
}

static void
frame_init(void)
{
	int i;

	for (i = 0 ; i < COS_MAX_MEMORY-1 ; i++) {
		frames[i].c.free = &frames[i+1];
		frames[i].nmaps  = 0;
	}
	frames[COS_MAX_MEMORY-1].c.free = NULL;
	freelist = &frames[0];
}

#define NREGIONS 4

extern struct cos_component_information cos_comp_info;


static inline void
mm_init(void)
{
	/* printc("core %ld: mm init as thread %d\n", cos_cpuid(), cos_get_thd_id()); */

	/* /\* Expanding VAS. *\/ */
	/* printc("mm expanding %lu MBs @ %p\n", (NREGIONS-1) * round_up_to_pgd_page(1) / 1024 / 1024,  */
	/*        (void *)round_up_to_pgd_page((unsigned long)&cos_comp_info.cos_poly[1])); */
	/* if (cos_vas_cntl(COS_VAS_SPD_EXPAND, cos_spd_id(),  */
	/* 		 round_up_to_pgd_page((unsigned long)&cos_comp_info.cos_poly[1]),  */
	/* 		 (NREGIONS-1) * round_up_to_pgd_page(1))) { */
	/* 	printc("MM could not expand VAS\n"); */
	/* 	BUG(); */
	/* } */

	frame_init();
	printc("core %ld: mm init done\n", cos_cpuid());
}

/* static inline void */
/* mm_init(void) */
/* { */
/* 	static int first = 1; */
/* 	printc("thread %d is doing mm init....(first %d)\n", cos_get_thd_id(), first); */
/* 	if (unlikely(first)) { */
/* 		first = 0; */
/* 		frame_init(); */
/* 	} */

/* } */

/*************************************/
/*** Memory allocation shenanigans ***/
/*************************************/

static inline struct frame *frame_alloc(void);
static inline int frame_index(struct frame *f);
static inline void *
__page_get(void)
{
	void *hp = cos_get_vas_page();
	struct frame *f;
	
again:
	/* printc("elephant\n"); */
	f= frame_alloc();
	assert(hp && f);

	if (unlikely(-1 == cos_mmap_cntl(COS_MMAP_GRANT, MAPPING_RW, cos_spd_id(), 
					 (vaddr_t)hp, frame_index(f)))) {
		printc("grant @ %p for frame %d failed...\n", hp, frame_index(f));
		/* if can not add into pgtbl (it must be used by
		 * another component), put the frame back to freelist,
		 * then try the next frame */
		frame_deref(f);
		goto again;
	}

	frame_ref(f);
	f->nmaps  = -1; 	 /* belongs to us... */
	f->c.addr = (vaddr_t)hp; /* ...at this address */

	/* Jiguo: track all pages used by mm */
	if (cos_mmap_cntl(COS_MMAP_SETROOT, MAPPING_RW, cos_spd_id(), 
			  (vaddr_t)hp, frame_index(f))) {
		assert(0);
	}

	return hp;
}
/* __page_get(void) */
/* { */
/* 	struct frame *f = frame_alloc(); */
/* 	void *hp = NULL; */
/* 	/\* If a page is not removed from page table after a fault, we */
/* 	 * need find the next available page -- Jiguo C^3 only *\/ */
/* again:     */
/* 	/\* printc("elephant\n"); *\/ */
/* 	hp = cos_get_vas_page(); */
/* 	assert(hp && f); */
/* 	if (cos_mmap_cntl(COS_MMAP_GRANT, MAPPING_RW, cos_spd_id(),  */
/* 			  (vaddr_t)hp, frame_index(f))) { */
/* 		printc("grant @ %p for frame %d\n", hp, frame_index(f)); */
/* 		/\* BUG(); *\/ */
/* 		goto again; */
/* 	} */
/* 	frame_ref(f); */
/* 	f->nmaps  = -1; 	 /\* belongs to us... *\/ */
/* 	f->c.addr = (vaddr_t)hp; /\* ...at this address *\/ */
	
/* 	/\* Jiguo: C^3 MM. So we can remove all allocated frame id for MM in __get_page *\/ */
/* 	if (cos_mmap_cntl(COS_MMAP_SETROOT, 0, cos_spd_id(), (vaddr_t)hp, frame_index(f))) { */
/* 		assert(0); */
/* 	} */

/* 	return hp; */
/* } */
#define CPAGE_ALLOC() __page_get()
#include <cpage_alloc.h>

#define CSLAB_ALLOC(sz)   cpage_alloc()
#define CSLAB_FREE(x, sz) cpage_free(x)
#include <cslab.h>

#define CVECT_ALLOC() cpage_alloc()
#define CVECT_FREE(x) cpage_free(x)
#include <cvect.h>

/**********************************************/
/*** Virtual address tracking per component ***/
/**********************************************/

CVECT_CREATE_STATIC(comps);
struct comp_vas {
	int nmaps, spdid;
	cvect_t *pages;
};
CSLAB_CREATE(cvas, sizeof(struct comp_vas));

static struct comp_vas *
cvas_lookup(spdid_t spdid)
{ return cvect_lookup(&comps, spdid); }

static struct comp_vas *
cvas_alloc(spdid_t spdid)
{
	struct comp_vas *cv;

	/* printc("cvas_alloc for spd %d\n", spdid); */

	/* assert(!cvas_lookup(spdid)); */
	if ((cv = cvas_lookup(spdid))) {
		cvect_del(&comps, cv->spdid);
	}
	assert(!cvas_lookup(spdid));
	cv = cslab_alloc_cvas();
	if (!cv) goto done;
	cv->pages = cvect_alloc();
	if (!cv->pages) goto free;
	cvect_init(cv->pages);
	cvect_add(&comps, cv, spdid);
	cv->nmaps = 0;
	cv->spdid = spdid;
done:
	return cv;
free:
	cslab_free_cvas(cv);
	cv = NULL;
	goto done;
}

static void
cvas_ref(struct comp_vas *cv)
{
	assert(cv);
	cv->nmaps++;
}

static void 
cvas_deref(struct comp_vas *cv)
{
	assert(cv && cv->nmaps > 0);
	cv->nmaps--;
	if (cv->nmaps == 0) {
		cvect_free(cv->pages);
		cvect_del(&comps, cv->spdid);
		cslab_free_cvas(cv);
	}
}

/**************************/
/*** Mapping operations ***/
/**************************/
struct mapping {
	u16_t   flags;
	spdid_t spdid;
	vaddr_t addr;

	struct frame *f;
	/* child and sibling mappings */
	struct mapping *p, *c, *_s, *s_;
} __attribute__((packed));
CSLAB_CREATE(mapping, sizeof(struct mapping));


static void
print_mapping(struct mapping *m)
{
	if (!m) return;
	printc("mapping.....\n");
	printc("spd %d addr %p flags %d\n", m->spdid, m->addr, m->flags);
}

/* Jiguo: After fault, there might old content left in the cslab. So
 * clean it after each cslab_alloc */
static void
cslab_mapping_reset(struct mapping *m)
{
	assert(m);

	m->flags = 0;
	m->spdid = 0;
	m->addr  = 0;

	m->f = m->p = m->c = m->_s = m->s_ = NULL;
	
	return;
}

static void
mapping_init(struct mapping *m, spdid_t spdid, vaddr_t a, struct mapping *p, struct frame *f)
{
	assert(m && f);
	INIT_LIST(m, _s, s_);
	m->f     = f;
	m->flags = 0;
	m->spdid = spdid;
	m->addr  = a;
	m->p     = p;
	if (p) {
		m->flags = p->flags;
		if (!p->c) p->c = m;
		else       ADD_LIST(p->c, m, _s, s_);
	}
}

static struct mapping *
mapping_lookup(spdid_t spdid, vaddr_t addr)
{
	struct comp_vas *cv = cvas_lookup(spdid);

	if (!cv) return NULL;
	return cvect_lookup(cv->pages, addr >> PAGE_SHIFT);
}

/* Make a child mapping */
static struct mapping *
mapping_crt(struct mapping *p, struct frame *f, spdid_t dest, vaddr_t to, int flags, int exist)
{
	struct comp_vas *cv = cvas_lookup(dest);
	struct mapping *m = NULL;
	long idx = to >> PAGE_SHIFT;
	
	assert(!p || p->f == f);
	assert(dest && to);

	/* no vas structure for this spd yet... */
	if (!cv) {
		/* printc("mapping_crt: cvas_alloc for spd %d\n", dest); */
		cv = cvas_alloc(dest);
		if (!cv) goto done;
		assert(cv == cvas_lookup(dest));
	}
	assert(cv->pages);
	if (cvect_lookup(cv->pages, idx)) {
		printc("a test msg\n");
		goto collision;
	}

	cvas_ref(cv);
	m = cslab_alloc_mapping();
	if (!m) goto collision;
	
	/* here is one issue: after fault, the memory from the heap
	 * can be reused with something left, which can cause wild
	 * pointer. So memset to 0 here. Some overhead though... TODO:
	 * track the heap usage and reset them if necessary. For now,
	 * just live with this overhead. */
	/* memset(m, 0, sizeof(struct mapping)); */
	cslab_mapping_reset(m);

	/* only add to the page table if not exist */
	if (!exist) {
		int tmp = cos_mmap_cntl(COS_MMAP_GRANT, flags, dest, to, frame_index(f));
		if (tmp && tmp != -1) {  // -1 means the entry is already in the table
			printc("mem_man: could not grant at %x:%p (ret %d)\n", dest, to, tmp);
			goto no_mapping;
		}
	}

	mapping_init(m, dest, to, p, f);
	assert(!p || frame_nrefs(f) > 0);
	frame_ref(f);
	assert(frame_nrefs(f) > 0);
	if (cvect_add(cv->pages, m, idx)) BUG();
done:
	return m;
no_mapping:
	cslab_free_mapping(m);
collision:
	cvas_deref(cv);
	m = NULL;
	goto done;
}

/* Take all decedents, return them in a list. */
static struct mapping *
__mapping_linearize_decendents(struct mapping *m)
{
	struct mapping *first, *last, *c, *gc;
	
	first = c = m->c;
	m->c = NULL;
	if (!c) return NULL;
	
	do {
		last = LAST_LIST(first, _s, s_);
		c->p = NULL;
		gc = c->c;
		c->c = NULL;
		/* add the grand-children onto the end of our list of decedents */
		if (gc) APPEND_LIST(last, gc, _s, s_);
		c = FIRST_LIST(c, _s, s_);
	} while (first != c);
	
	return first;
}

static void
__mapping_destroy(struct mapping *m)
{
	struct comp_vas *cv;
	int idx;
	assert(m);
	assert(EMPTY_LIST(m, _s, s_));
	assert(m->p == NULL);
	assert(m->c == NULL);
	cv = cvas_lookup(m->spdid);

	if (!cv) goto done;  // Jiguo: add this to avoid trigger the fault when system exits

	assert(cv && cv->pages);
	assert(m == cvect_lookup(cv->pages, m->addr >> PAGE_SHIFT));
	cvect_del(cv->pages, m->addr >> PAGE_SHIFT);
	cvas_deref(cv);

done:
	idx = cos_mmap_cntl(COS_MMAP_REVOKE, 0, m->spdid, m->addr, 0);
	/* if (m->spdid == 17 || m->spdid == 18 || m->spdid == 19) { */
	/* 	printc("mapping_destroy -- "); */
	/* 	print_mapping(m); */
	/* 	printc("idx %d frame_index(m->f) %d\n", */
	/* 	       idx, frame_index(m->f)); */
	/* } */
	assert(idx == frame_index(m->f));
	frame_deref(m->f);
	cslab_free_mapping(m);
}

static void
mapping_del_children(struct mapping *m)
{
	struct mapping *d, *n; 	/* decedents, next */

	assert(m);
	d = __mapping_linearize_decendents(m);
	while (d) {
		n = FIRST_LIST(d, _s, s_);
		REM_LIST(d, _s, s_);
		__mapping_destroy(d);
		d = (n == d) ? NULL : n;
	}
	assert(!m->c);
}

static void
mapping_del(struct mapping *m)
{
	assert(m);
	mapping_del_children(m);
	assert(!m->c);
	if (m->p && m->p->c == m) {
		if (EMPTY_LIST(m, _s, s_)) m->p->c = NULL;
		else                       m->p->c = FIRST_LIST(m, _s, s_);
	}
	m->p = NULL;
	REM_LIST(m, _s, s_);
	__mapping_destroy(m);
}

/**********************************/
/*** Public interface functions ***/
/**********************************/

static vaddr_t 
__mman_get_page(spdid_t spd, vaddr_t addr, int flags, int exist)
{
	struct frame *f;
	struct mapping *m = NULL;
	vaddr_t ret = -1;
	
	WAIT_FAULT();

	LOCK();

	/* printc("mman_get_page: thd %d from spd %d addr %p (test_control %d flags %d)\n", */
	/*        cos_get_thd_id(), spd, addr, test_control, flags); */

	if (unlikely(exist)) {
		int fidx = cos_mmap_introspect(COS_MMAP_INTROSPECT_FRAME, 0, spd, addr, 0);
		/* printc("MMAP_INTROSPECT_FRAME ret %d\n",fidx); */
		f = frame_alloc_index(fidx);
		if (!f) goto done; 	/* -ENOMEM */
		/* printc("frame_allo_index ret %d\n", frame_index(f)); */
		assert(frame_nrefs(f) == 0);
		m = mapping_crt(NULL, f, spd, addr, flags, exist);
	} else {
		/* if (cos_mmap_introspect(COS_MMAP_INTROSPECT_ROOTPAGE,  */
		/* 			flags, spd, addr, 0)){ */
		/* 	printc("!!!! this is a root page already in the pgtbl\n"); */
		/* 	ret = -ECHILD;   // error and addr is in the pgtbl already */
		/* 	goto done; */
		/* } */

		f = frame_alloc();
		if (!f) goto done; 	/* -ENOMEM */
		assert(frame_nrefs(f) == 0);
		m = mapping_crt(NULL, f, spd, addr, flags, exist);
	}
	
	
#if (RECOVERY_ENABLE == 1) && defined(TEST_MM_GET_PAGE)
	if (spd == 17 && cos_get_thd_id() == 13 && test_control++ >= 4) {
		printc("trigger fault in mman_get_page: thd %d from spd %d addr %p\n",
		       cos_get_thd_id(), spd, addr);
		assert(0);
	}
#endif
	
	if (!m) goto dealloc;
	f->c.m = m;
	assert(m->addr == addr);
	assert(m->spdid == spd);
	assert(m == mapping_lookup(spd, addr));
	ret = m->addr;
	
	if (!exist && 
	    cos_mmap_cntl(COS_MMAP_SETROOT, flags, spd, addr, frame_index(f))) {
		printc("tracking root page failed\n");
		assert(0);
	}
	
done:
	UNLOCK();
	return ret;
dealloc:
	frame_deref(f);
	goto done;		/* -EINVAL */
}

vaddr_t 
mman_get_page(spdid_t spd, vaddr_t addr, int flags) 
{
	return __mman_get_page(spd, addr, flags, 0);
}

vaddr_t 
mman_get_page_exist(spdid_t spd, vaddr_t addr) 
{
	return __mman_get_page(spd, addr, 0, 1);
}

vaddr_t 
__mman_alias_page(spdid_t s_spd, vaddr_t s_addr, u32_t d_spd_flags, vaddr_t d_addr)
{
	struct mapping *m, *n;
	vaddr_t ret = 0;
	spdid_t d_spd;
	int flags;
	
	d_spd = d_spd_flags >> 16;
	flags = d_spd_flags & 0xFFFF;
	
	WAIT_FAULT();

/* #ifdef BENCHMARK_MEAS_INV_OVERHEAD_MM */
/* 	if (cos_get_thd_id() == 13) return ret; */
/* #endif */

	/* if (s_spd != 5) { */
	/* 	printc("__mman_alias_page: s_spd %d s_addr %p d_spd %d d_addr %p\n", */
	/* 	       s_spd, s_addr, d_spd, d_addr); */
	/* } */
		
	LOCK();

	m = mapping_lookup(s_spd, s_addr);
	if (unlikely(!m)) {
		/* printc("__mman_alias_page: can not find mapping for s_spd %d s_addr %p\n", */
		/*        s_spd, s_addr); */
		/* printc("__mman_alias_page: now introspect root page (flags %d)\n", */
		/*        flags); */
		if (cos_mmap_introspect(COS_MMAP_INTROSPECT_ROOTPAGE, 
					flags, s_spd, s_addr, 0)){
			/* printc("!!!! this is a root page\n"); */
			ret = -ECHILD;   // error and s_addr is the root page
		} else {
			ret = -EINVAL;
		}
		goto done;
	}
	assert(m && m->f);

#if (RECOVERY_ENABLE == 1) && defined(TEST_MM_ALIAS_PAGE)
	/* if (s_spd == 18 && cos_get_thd_id() == 13) { */
	/* 	printc("mman_alias_page: thd %d spd %ld passed s_spd %d dest_spd %d (num %d)\n", */
	/* 	       cos_get_thd_id(), cos_spd_id(), s_spd, d_spd, test_control++); */
	/* } */

	if (s_spd == 18 && cos_get_thd_id() == 13 && test_control++ == 2) {
		printc("trigger fault in mman_alias_page: thd %d spd %ld passed s_spd %d dest_spd %d\n", cos_get_thd_id(), cos_spd_id(), s_spd, d_spd);
		assert(0);
	}
#endif

	n = mapping_crt(m, m->f, d_spd, d_addr, flags, 0);
	if (!n) goto done;

	assert(n->addr  == d_addr);
	assert(n->spdid == d_spd);
	assert(n->p     == m);
	ret = d_addr;

	/* if (n->spdid == 17 || n->spdid == 18 || n->spdid == 19) { */
	/* 	printc("mapping_aias -- m"); */
	/* 	print_mapping(m); */
	/* 	printc("frame_index(m->f) %d\n", frame_index(m->f)); */
	/* 	printc("frame_index(n->f) %d\n", frame_index(n->f)); */
	/* } */

done:
	UNLOCK();
	/* printc("in alias function.....return %p\n", ret); */
	return ret;
}


/* /\* rebuild m's children before we delete all. First we */
/*  * switch to the recovery thread. Then upcall into spd */
/*  * and replay the alias, which will rebuild all */
/*  * siblings. Then iterate all siblings (recursively) */
/*  * until no more siblings (DFS) *\/ */
/* static void  */
/* rebuild_all_alias(spdid_t spd, vaddr_t addr)  */
/* { */
/* 	spdid_t rec_spd; */
/* 	vaddr_t rec_addr; */
/* 	rec_spd = spd; */
/* 	rec_addr = addr;		 */

/* 	printc("mm: recovery_upcall passing rec_spd %d rec_addr %p\n", */
/* 	       rec_spd, rec_addr); */
/* 	recovery_upcall(cos_spd_id(), COS_UPCALL_RECOVERY, rec_spd, rec_addr); */
/* 	printc("mm: return from recovery_upcall passing rec_spd %d rec_addr %p\n", */
/* 	       rec_spd, rec_addr); */
	
/* 	struct mapping *rec_m = mapping_lookup(rec_spd, rec_addr); */
/* 	assert(rec_m); */
/* 	struct mapping *rec_c = rec_m->c; */
/* 	printc("there is child\n"); */
/* 	if (!rec_c) return; */
/* 	struct mapping *rec_s; */
/* 	printc("ready to rebuild all its other children\n"); */
/* 	for (rec_s = FIRST_LIST(rec_c, _s, s_) ;  */
/* 	     rec_s != rec_c;  */
/* 	     rec_s = FIRST_LIST(rec_s, _s, s_)) { */
/* 		rec_spd = rec_s->spdid; */
/* 		rec_addr = rec_s->addr; */
/* 		/\* be careful with the recursion depth, this should */
/* 		 * change to the stack, not recursive *\/ */
/* 		printc("mm: recovery_upcall one child !!!! passing rec_spd %d rec_addr %p\n", */
/* 		       rec_spd, rec_addr); */
/* 		rebuild_all_alias(rec_spd, rec_addr); */
/* 	} */

/* 	return; */
/* } */

int 
mman_revoke_page(spdid_t spd, vaddr_t addr, int flags)
{
	struct mapping *m;
	int ret = 0;

	WAIT_FAULT();

	/* printc("in mman_revoke by thd %d\n", cos_get_thd_id()); */

	LOCK();
	m = mapping_lookup(spd, addr);
	if (!m) {
		ret = -EINVAL;
		goto done;
		
		/* UNLOCK(); */
		/* int fr_idx = (int)cos_mmap_introspect(COS_MMAP_INTROSPECT_FRAME, */
		/* 				      0, spd, addr, 0); */
		/* printc("mman_revoke: can not find mapping. Intro fr_idx is %d\n", fr_idx); */
		/* if (!fr_idx) { */
		/* 	ret = -1; */
		/* 	goto done;    // real an error, otherwise create a new map */
		/* } */
		/* m = mapping_crt(NULL, &frames[fr_idx], spd, addr, flags); */
		/* assert(m == mapping_lookup(spd,addr)); */

		/* rebuild_all_alias(spd, addr); */
		
		/* LOCK(); */
	}

#if (RECOVERY_ENABLE == 1) && defined(TEST_MM_REVOKE_PAGE)
	if (spd == 17 && cos_get_thd_id() == 13 && test_control++ == 1) {
		printc("trigger fault in mman_revoke_page: thd %d spd %ld passed spd %d\n", 
		       cos_get_thd_id(), cos_spd_id(), spd);
		assert(0);
	}
#endif

	/* printc("mman_revoke: del children of page %p .....\n", addr); */

	mapping_del_children(m);

	/* printc("mman_revoke: revoke page %p done!!!!\n", addr); */

	/* /\* For fault coverage test only :jiguo *\/ */
	/* mapping_del(m);    // this should not be in revoke -- Jiguo */
done:
	UNLOCK();
	return ret;
}


int
mman_release_page(spdid_t spd, vaddr_t addr, int flags)
{
	struct mapping *m;
	int ret = 0;

	LOCK();

	/* printc("mman_release_page (thd %d) addr %p\n", cos_get_thd_id(), (void *)addr); */

	/* Jiguo: when flags > 0, it is used for reflection
	 * purpose. flags == src_spd from which we want to revoke
	 * pages */
	if (flags > 0) spd = flags;

	m = mapping_lookup(spd, addr);
	if (!m) {
		ret = -1;	/* -EINVAL */
		goto done;
	}
	mapping_del(m);
done:
	UNLOCK();
	return ret;
}

void mman_print_stats(void) {}

void mman_release_all(void)
{
	int i;

	LOCK();
	/* kill all mappings in other components */
	for (i = 0 ; i < COS_MAX_MEMORY ; i++) {
		struct frame *f = &frames[i];
		struct mapping *m;

		if (frame_nrefs(f) <= 0) continue;
		m = f->c.m;
		assert(m);
		mapping_del(m);
	}
	UNLOCK();
}

vaddr_t
mman_reflect(spdid_t spd, int src_spd, int cnt) {return 0;}

/*******************************/
/*** The base-case scheduler ***/
/*******************************/

#include <sched_hier.h>

int  sched_init(int reboot)   { printc("mem sched_init\n");return 0; }
extern void parent_sched_exit(void);

PERCPU_ATTR(static volatile, int, initialized_core); /* record the cores that still depend on us */

void
sched_exit(void)
{
	int i;
	printc("sched_exit in MM\n");
	*PERCPU_GET(initialized_core) = 0;
	if (cos_cpuid() == INIT_CORE) {
		/* The init core waiting for all cores to exit. */
		for (i = 0; i < NUM_CPU ; i++)
			if (*PERCPU_GET_TARGET(initialized_core, i)) i = 0;
		/* Don't delete the memory until all cores exit */
		mman_release_all(); 
	}
	parent_sched_exit();
}

int sched_isroot(void) { return 1; }

int
sched_child_get_evt(spdid_t spdid, struct sched_child_evt *e, int idle, unsigned long wake_diff) { BUG(); return 0; }

extern int parent_sched_child_cntl_thd(spdid_t spdid);

int
sched_child_cntl_thd(spdid_t spdid)
{
	if (parent_sched_child_cntl_thd(cos_spd_id())) BUG();
	if (unlikely(cos_sched_introspect(COS_SCHED_HAS_PARENT, spdid, 0))) return 0;
	if (cos_sched_cntl(COS_SCHED_PROMOTE_CHLD, 0, spdid)) BUG();
	if (cos_sched_cntl(COS_SCHED_GRANT_SCHED, cos_get_thd_id(), spdid)) BUG();

	return 0;
}

int
sched_child_thd_crt(spdid_t spdid, spdid_t dest_spd) { BUG(); return 0; }


/* static struct comp_vas *cvas_alloc(spdid_t spdid); */
/* static void */
/* frame_reset(void) */
/* { */
/* 	int i, indx = 0; */
	
/* 	while(1) { */
/* 		/\* printc("mm: frame_re_init before (indx %d)\n", indx); *\/ */
/* 		indx = cos_mmap_introspect(COS_MMAP_INTROSPECT_INDEX, 0, 0, 0, indx+1); */
/* 		if (!indx) break;  // zero means no more frame needs to be reserved */
/* 		/\* printc("mm: frame_re_init after (indx %d)\n", indx); *\/ */
/* 		frames[indx-1].c.free = &frames[indx+1];   // skipped the reserved one */
/* 	} */

/* 	// why do this??  */
/* 	/\* // not work with spd 5, 6....?? *\/ */
/* 	/\* struct comp_vas *cv = cvas_alloc(10); *\/ */
/* 	/\* assert(cv); *\/ */
/* 	/\* cv = cvas_alloc(11); *\/ */
/* 	/\* assert(cv); *\/ */

/* 	/\* for (i = 0; i < MAX_NUM_SPDS; i++) { *\/ */
/* 	/\* 	if(cos_mmap_introspect(COS_MMAP_INTROSPECT_SPD, 0, i, 0, 0)){ *\/ */
/* 	/\* 		printc("mm: frame_re_init found spd %d\n", i); *\/ */
/* 	/\* 		if (i == 5) continue; *\/ */
/* 	/\* 		struct comp_vas *cv = cvas_alloc(i); *\/ */
/* 	/\* 		assert(cv); *\/ */
/* 	/\* 	} *\/ */
/* 	/\* } *\/ */
	
/* 	return; */
/* } */

void cos_upcall_fn(upcall_type_t t, void *arg1, void *arg2, void *arg3)
{
	/* printc("upcall type %d, core %ld, thd %d, args %p %p %p\n", */
	/*        t, cos_cpuid(), cos_get_thd_id(), arg1, arg2, arg3); */
	switch (t) {
	case COS_UPCALL_THD_CREATE:
		if (cos_cpuid() == INIT_CORE) {
			int i;
			for (i = 0; i < NUM_CPU; i++)
				*PERCPU_GET_TARGET(initialized_core, i) = 0;
			mm_init(); 
		} else {
			/* Make sure that the initializing core does
			 * the initialization before any other core
			 * progresses */
			while (*PERCPU_GET_TARGET(initialized_core, INIT_CORE) == 0) ;
		}
		*PERCPU_GET(initialized_core) = 1;
		break;
	case COS_UPCALL_REBOOT:
		/* printc("mm: cos_upcall here to reboot 2 (passed arg1 %d)\n", (int)arg1); */
		mm_init();
		
		/* Jiguo: here is the situation 1) we need reserve
		 * physical frames for already allocated ones in other
		 * spds, and 2) remove allocated frames for MM itself
		 * in __page_get  */

               /* Jiguo C^3 MM: initialize the frame free list by
		* introspecting the kernel tracked frame-page. When
		* uReboot MM, the root page should be reused and for
		* simplicity, we find all tracked root page and
		* reserve their frame id. This is because the pages
		* are only related by frame id mainted by MM, not
		* explicitly over the client interface (such as
		* torrent id) */

		if (cos_mmap_introspect(COS_MMAP_RESET_MM_FRAME, 0, cos_spd_id(), 0, 0))
			assert(0);
		
		/* frame_reset(); */
		break;
	case COS_UPCALL_SWIFI_BEFORE:   // prepare for swifi
	{
		swifi_ready = 1; // now other thread can spin for inject fault
		break;
	}
	case COS_UPCALL_SWIFI_AFTER:   // allow other thread to proceed 
	{
		swifi_ready = 0; // now other thread can continue
		break;
	}
	default:
		BUG(); return;
	}

	return;
}
