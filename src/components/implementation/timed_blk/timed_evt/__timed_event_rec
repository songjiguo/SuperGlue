/**
 * Copyright 2008 by Boston University.  All rights reserved.
 *
 * Redistribution of this file is permitted under the GNU General
 * Public License v2.
 *
 * Initial Author: Gabriel Parmer, gabep1@cs.bu.edu, 2008
 */

#define COS_FMT_PRINT

#include <cos_component.h>
#include <cos_debug.h>
#include <print.h>
#include <cos_time.h>
#include <cos_list.h>
#include <cos_vect.h>
#include <cos_alloc.h>

#include <mem_mgr_large.h>
#include <valloc.h>

#include <c3_test.h>

#include <pgfault.h>

#include <timed_blk.h>
#include <periodic_wake.h>

#include <evt.h>  // Jiguo: now have thread block through event

#if (RECOVERY_ENABLE == 1)
#include <c3_test.h>
#endif
unsigned int swifi_ready = 0;  // explicitly initialize to 0

#include <sched.h>
#include "../../sched/cos_sched_sync.h"

#include <sys/param.h> 		/* MIN/MAX */
#include <res_spec.h> /* For creating timer thread */
/* Lets save some typing... */
#define TAKE(spdid)							\
	if (sched_component_take(spdid)) return -1;			\

#define RELEASE(spdid)	if (sched_component_release(spdid)) return -1;

static int test_num = 0;

extern int sched_cs_state(spdid_t spdid);

/* Monotonically increasing timer counting clicks */
typedef unsigned long long event_time_t;
static volatile event_time_t ticks = 0;
const event_time_t TIMER_NO_EVENTS = ~0;
unsigned long cyc_per_tick;

#define TE_TIMED_OUT 0x1
#define TE_BLOCKED   0x2
#define TE_PERIODIC  0x4

struct thread_event {
	event_time_t event_expiration;
	unsigned short int thread_id, flags;
	struct thread_event *next, *prev;

	long evt;   // Jiguo: Now each created timed thread is associated with an event

	/* if flags & TE_PERIODIC */
	unsigned int period, missed;
	unsigned short int dl, dl_missed, need_restart; /* missed deadlines */
	unsigned int samples, miss_samples;
	long long lateness_tot, miss_lateness_tot;
	long long completion;
};

static struct thread_event events, periodic;

COS_VECT_CREATE_STATIC(thd_evts);
COS_VECT_CREATE_STATIC(thd_periodic);

/* 
 * FIXME: to make this predictable (avoid memory allocation in the
 * must-be-predictable case, we should really cos_vect_add_id when we
 * first find out about the possibility of the thread making any
 * invocations.
 */
static struct thread_event *__te_get(unsigned short int tid, cos_vect_t *v)
{
	struct thread_event *te;

	te = cos_vect_lookup(v, tid);
	if (NULL == te) {
		/* printc("malloc 1\n"); */
		te = malloc(sizeof(struct thread_event));
		/* printc("malloc 2\n"); */
		if (NULL == te) return NULL;
		memset(te, 0, sizeof(struct thread_event));
		te->thread_id = tid;
		INIT_LIST(te, next, prev);
		if (tid != cos_vect_add_id(v, te, tid)) return NULL;
	}
	return te;
}

static struct thread_event *te_pget(unsigned short int tid)
{
	return __te_get(tid, &thd_periodic);
}

static struct thread_event *te_get(unsigned short int tid)
{
	return __te_get(tid, &thd_evts);
}

//#define USEC_PER_SEC 1000000
//static unsigned int usec_per_tick = 0;

/* 
 * Return 1 if the inserted event is closer in the future than any
 * others, 0 otherwise.
 */
static int __insert_event(struct thread_event *te, struct thread_event *events)
{
	struct thread_event *tmp;

	assert(NULL != te);
	assert(te->event_expiration);
	assert(EMPTY_LIST(te, next, prev));
	assert(events->next && events->prev);
	if (EMPTY_LIST(events, next, prev)) {
		ADD_LIST(events, te, next, prev);
	} else for (tmp = FIRST_LIST(events, next, prev) ;
		    ; /* condition built into body (see break;) */
		    tmp = FIRST_LIST(tmp, next, prev)) {
		assert(tmp);
		struct thread_event *prev_te = LAST_LIST(tmp, next, prev);
		assert(prev_te);
		assert(tmp->prev && tmp->next);
		/* We found our place in the list OR end of list.
		 * Either way, insert before this position */
		if (tmp->event_expiration > te->event_expiration ||
		    events == tmp) {
			ADD_LIST(prev_te, te, next, prev);
			assert(prev_te->next == te && te->prev == prev_te);
			assert(te->next == tmp && tmp->prev == te);
			break;
		}
		assert(tmp->next && tmp->prev);
	}
	
	assert(!EMPTY_LIST(events, next, prev));
	assert(!EMPTY_LIST(te, next, prev));

	return 0;
}

static int insert_event(struct thread_event *te)
{
	return __insert_event(te, &events);
}

static int insert_pevent(struct thread_event *te)
{
	return __insert_event(te, &periodic);
}

static struct thread_event *find_remove_event(unsigned short int thdid)
{
	struct thread_event *tmp;

	for (tmp = FIRST_LIST(&events, next, prev);
	     tmp != &events;
	     tmp = FIRST_LIST(tmp, next, prev)) {
		if (tmp->thread_id == thdid) {
			REM_LIST(tmp, next, prev);
			assert(events.next && events.prev);
			return tmp;
		}
	}
	return NULL;
}

static void __event_expiration(event_time_t time, struct thread_event *events)
{
	spdid_t spdid = cos_spd_id();

	struct thread_event *tmp, *next_te;

	assert(TIMER_NO_EVENTS != time);

	for (tmp = FIRST_LIST(events, next, prev) ;
	     tmp != events && tmp->event_expiration <= time ; 
	     tmp = next_te) {
		u8_t b;
		unsigned short int tid;

		assert(tmp);
		next_te = FIRST_LIST(tmp, next, prev);
		assert(next_te && next_te->prev == tmp && tmp->next == next_te);
		tmp->flags |= TE_TIMED_OUT;
		REM_LIST(tmp, next, prev);
		b = tmp->flags & TE_BLOCKED;
		tmp->flags &= ~TE_BLOCKED;
		tid = tmp->thread_id;

		if (tmp->flags & TE_PERIODIC) {
			/* thread hasn't blocked? deadline miss! */
			if (!b) {
				tmp->dl_missed++;
				tmp->need_restart++;
				if (!tmp->missed) { /* first miss? */
					tmp->missed = 1;
					if (tmp->completion) {
						/* compute the lateness of 
						   last task finished on time */
						long long t;
						rdtscll(t);
						tmp->lateness_tot += -(t - tmp->completion);
						tmp->samples++;
 					}
					/* save time of deadline, unless we
					 * have saved the time of an earlier
					 * deadline miss */
					rdtscll(tmp->completion);
					tmp->miss_samples++;
					tmp->samples++;
				}
			} else {
				assert(!tmp->missed); /* on time, compute lateness */
				long long t;
				assert (tmp->completion) ;
				rdtscll(t);
				tmp->lateness_tot += -(t - tmp->completion);
				tmp->samples++;
				tmp->completion = 0;
			}

			tmp->dl++;
			/* Next periodic deadline! */
			tmp->event_expiration += tmp->period;
			insert_pevent(tmp);
		}

		/* if (b) sched_wakeup(spdid, tmp->thread_id); */
		/* We don't have to deallocate the thread_events as
		 * they are stack allocated on the sleeping
		 * threads. */

		// Jiguo: wake up the thread through evt
		if (b) {
			/* printc("timed_evt: event_expiration evt_trigger (tdh %d evt %d)\n", */
			/*        cos_get_thd_id(), tmp->evt); */

			if (sched_component_release(spdid)) {
				prints("fprr: scheduler lock release failed!!!");
				BUG();
			}
			
			evt_trigger(spdid, tmp->evt);

			if (sched_component_take(spdid)) {
				prints("fprr: scheduler lock failed!!!");
				BUG();
			}
		}
	}
}

/* 
 * This should only be called from the event thread (which has the
 * highest priority), so we don't need to be preempted before waking
 * all threads.
 */
static void event_expiration(event_time_t time)
{
	__event_expiration(time, &periodic);
	__event_expiration(time, &events);

	return;
}

static inline event_time_t next_event_time(void)
{
	event_time_t e = TIMER_NO_EVENTS, p = TIMER_NO_EVENTS;

	e = EMPTY_LIST(&events, next, prev) ? 
		TIMER_NO_EVENTS :
		FIRST_LIST(&events, next, prev)->event_expiration;
	p = EMPTY_LIST(&periodic, next, prev) ? 
		TIMER_NO_EVENTS : 
		FIRST_LIST(&periodic, next, prev)->event_expiration;
	/* assume here that TIMER_NO_EVENTS > all other values */
	return MIN(e, p);
}

/**
 * FIXME: store the spdid blocking thread is invoking from, and make
 * sure that the wakeup request comes from the same component
 */
/*
 * FIXME: allow amnt to be specified in time units rather than ticks.
 */
int timed_event_block(spdid_t spdinv, unsigned int amnt)
{
	spdid_t spdid = cos_spd_id();
	struct thread_event *te;
	int block_time;
	event_time_t t;

	long evt;

	if (amnt == 0) return 0;
	/* 
	 * Convert from usec to ticks
	 *
	 * +2 here as we don't know how far through the current clock
	 * tick we are _and_ we don't know how far into the clock tick
	 * the wakeup time is.  The sleep is supposed to be for _at
	 * least_ amnt clock ticks, thus here we are conservative.
	 */
	//amnt = (amnt/(unsigned int)usec_per_tick) + 2;
	/* update: seems like +1 should be enough */
	amnt++;

	/* //Jiguo: a thread can already take the critical section and */
        /* // fail before release, so check if the critical section is */
	/* // being hold here */
	/* if (unlikely(sched_cs_state(cos_spd_id()))) { */
	/* 	sched_component_release(cos_spd_id()); */
	/* } */

	TAKE(spdid);
	te = te_get(cos_get_thd_id());
	if (NULL == te) BUG();
	assert(EMPTY_LIST(te, next, prev));

	te->thread_id = cos_get_thd_id();
	te->flags &= ~TE_TIMED_OUT;
	te->flags |= TE_BLOCKED;

	// Jiguo: a thread is associated with an event now
	evt = evt_split(cos_spd_id(), 0, 0);
	assert(evt > 0);
	te->evt = evt;

	ticks = sched_timestamp();
	/* printc("ticks %llu, amnt %d\n", ticks, amnt); */
	te->event_expiration = ticks + amnt;
	block_time = ticks;
   	assert(te->event_expiration > ticks);
	t = next_event_time();
	insert_event(te);
	assert(te->next && te->prev && !EMPTY_LIST(te, next, prev));
	RELEASE(spdid);

	if (t != next_event_time()) sched_timeout(spdid, amnt);

	// Jiguo: change to use event 
	long wait_ret;
redo:
	wait_ret = evt_wait(cos_spd_id(), te->evt);
	/* if return from the fault and the time is not expired, keep
	 * waiting. No need to take lock? */
	if (unlikely(wait_ret < 0 && !EMPTY_LIST(te, next, prev))) {
		printc("thd %d is going to call evt_wait in spd %ld again\n",
		       cos_get_thd_id(), cos_spd_id());
		goto redo;  
	}

	/* printc("thd %d after evt_wait in spd %ld\n", cos_get_thd_id(), cos_spd_id()); */
	assert(EMPTY_LIST(te, next, prev));

	if (te->flags & TE_TIMED_OUT) return TIMER_EXPIRED;

	/* 
	 * The event has already been removed from event list in
	 * event_expiration by the timeout thread.
	 * 
	 * Minus 1 here as we must report the amount of time we are
	 * sure we waited for.  As we don't know how far into the tick
	 * we were when we slept, and how far the wakeup is into a
	 * tick, we must account for this.
	 */
	return ((int)ticks - block_time - 1); //*usec_per_tick; /* expressed in ticks currently */
}

int timed_event_wakeup(spdid_t spdinv, unsigned short int thd_id)
{
	spdid_t spdid = cos_spd_id();
	struct thread_event *evt;

	TAKE(spdid);
	ticks = sched_timestamp();
	if (NULL == (evt = find_remove_event(thd_id))) {
		RELEASE(spdid);
		return 1;
	}
	RELEASE(spdid);
	assert(evt->thread_id == thd_id);

	return sched_wakeup(spdid, thd_id);
}


static long te_get_reset_lateness(struct thread_event *te)
{
	long long avg;

	if (0 == te->samples){
		if (!te->missed)
			return 0;	
		else
			te->samples = 1;
	}
	
	if (te->missed && te->completion){
		long long t;
		rdtscll(t);
		te->lateness_tot += (t - te->completion);
	}
	avg = te->lateness_tot / te->samples;
	avg = (avg >> 20) + ! ((avg & 1048575) == 0);/* right shift 20 bits and round up, 2^20 - 1 = 1048575 */
	
	te->lateness_tot = 0;
	te->samples = 0;

	return avg;
}

static long te_get_reset_miss_lateness(struct thread_event *te)
{
	long long avg;

	if (0 == te->miss_samples){
		if (!te->missed)
			return 0;
		else
			te->miss_samples = 1;
	}

	if (te->missed && te->completion){
		long long t;
		rdtscll(t);
		te->miss_lateness_tot += (t - te->completion);
	}

	avg = te->miss_lateness_tot / te->miss_samples;
	avg = (avg >> 20) + ! ((avg & 1048575) == 0);/* right shift 20 bits and round up, 2^20 - 1 = 1048575 */

	te->miss_lateness_tot = 0;
	te->miss_samples = 0;

	return avg;
}

long periodic_wake_get_lateness(unsigned short int tid)
{
	struct thread_event *te;
	spdid_t spdid = cos_spd_id();
	long ret;

	TAKE(spdid);
	te = te_pget(tid);
	if (NULL == te) BUG();
	if (!(te->flags & TE_PERIODIC)) {
		RELEASE(spdid);
		return 0;
	}
	ret = te_get_reset_lateness(te);
	RELEASE(spdid);
	
	return ret;
}

long periodic_wake_get_miss_lateness(unsigned short int tid)
{
	struct thread_event *te;
	spdid_t spdid = cos_spd_id();
	long ret;

	TAKE(spdid);
	te = te_pget(tid);
	if (NULL == te) BUG();
	if (!(te->flags & TE_PERIODIC)) {
		RELEASE(spdid);
		return 0;
	}
	ret = te_get_reset_miss_lateness(te);
	RELEASE(spdid);
	
	return ret;
}

int periodic_wake_get_misses(unsigned short int tid)
{
	struct thread_event *te;
	spdid_t spdid = cos_spd_id();
	int m;

	TAKE(spdid);
	te = te_pget(tid);
	if (NULL == te) BUG();
	if (!(te->flags & TE_PERIODIC)) {
		RELEASE(spdid);
		return -1;
	}
	m = te->dl_missed;
	te->dl_missed = 0;
	RELEASE(spdid);

	return m;
}

int periodic_wake_get_deadlines(unsigned short int tid)
{
	struct thread_event *te;
	spdid_t spdid = cos_spd_id();
	int m;

	TAKE(spdid);
	te = te_pget(tid);
	if (NULL == te) BUG();
	if (!(te->flags & TE_PERIODIC)) {
		RELEASE(spdid);
		return -1;
	}
	m = te->dl;
	te->dl = 0;
	RELEASE(spdid);

	return m;
}

int periodic_wake_get_period(unsigned short int tid)
{
	struct thread_event *te;
	spdid_t spdid = cos_spd_id();
	int p;

	TAKE(spdid);
	te = te_pget(tid);
	if (NULL == te) BUG();
	if (!(te->flags & TE_PERIODIC)) {
		RELEASE(spdid);
		return -1;
	}
	p = (int)te->period;
	RELEASE(spdid);

	return p;
}

/* Jiguo: the ticks is unsigned long long, but for now I assume this
 * can be hold by the register and return the ticks that a pte thread
 * is created. C3 needs to remember when the pte thread is created and
 * synchronize the thread with the original period. Assume all pte
 * threads are created in the first 2^32-1 ticks  */
static int __periodic_wake_create(spdid_t spdinv, unsigned int period, int exist)
{
	printc("thd %d calling period_wake_create\n", cos_get_thd_id());

	struct thread_event *te;
	unsigned short int tid = cos_get_thd_id();
	spdid_t spdid = cos_spd_id();
	event_time_t n, t;
	long evt;
	/* int ret = 0; */

	if (period < 1) return -1;

	TAKE(spdid);
	te = te_pget(tid);
	if (NULL == te) BUG();
	if (te->flags & TE_PERIODIC) {
		assert(!EMPTY_LIST(te, next, prev));
		REM_LIST(te, next, prev);
	}
	assert(EMPTY_LIST(te, next, prev));
	te->flags |= TE_PERIODIC;
	te->period = period;
	
#if (RECOVERY_ENABLE == 1) && defined(TEST_PTE_CREATE_BEFORE)
	/* printc("in periodic_wake_create: thd %d spd %d\n",  */
	/*        cos_get_thd_id(), spdinv);		 */
	/* test_num++; */
	/* if (spdinv == 16 && cos_get_thd_id() == 13 && test_num == 1) { */
	if (test_num++ > 1000) {
		printc("trigger fault in periodic_wake_create before: thd %d spd %d\n", 
		       cos_get_thd_id(), spdid);
		assert(0);
	}
#endif

// Jiguo: a thread is associated with an event now
	evt = evt_split(cos_spd_id(), 0, 0);
	assert(evt > 0);
	te->evt = evt;
	
	unsigned long creation_ticks;
	if (unlikely(exist)) {
		creation_ticks  = sched_get_creation_timestamp();
		printc("creation timestamp is %lu\n", creation_ticks);
	}

	ticks = sched_timestamp();

	/* ret   = ticks;   // Jiguo: see above assumption. This is only tracked once */

	if (likely(!exist)) {
		te->event_expiration = n = ticks + period;
	} else {
		te->event_expiration = n = creation_ticks + 
			period*((ticks - creation_ticks)/period + 1);
	}

	assert(n > ticks);
	printc("ticks %llu period %d expire %llu\n", 
	       ticks, period, te->event_expiration);

	t = next_event_time();
	assert(t > ticks);
	insert_pevent(te);
	if (t > n) sched_timeout(spdid, n-ticks);
	te->need_restart = 0;

	RELEASE(spdid);

#if (RECOVERY_ENABLE == 1) && defined(TEST_PTE_CREATE_AFTER)
	/* test_num++; */
	/* /\* printc("in periodic_wake_create: thd %d spd %d, test_num %d\n", *\/ */
	/* /\*        cos_get_thd_id(), spdinv, test_num); *\/ */
	/* if (spdinv == 16 && cos_get_thd_id() == 13 && test_num == 1) { */
	if (test_num++ > 1000) {
		printc("trigger fault in periodic_wake_create after: thd %d spd %d\n", 
		       cos_get_thd_id(), spdid);
		assert(0);
	}
#endif
	
        return 0;
	/* return ret;   // Jiguo: return the creation ticks */
}

int periodic_wake_create(spdid_t spdinv, unsigned int period)
{
	return __periodic_wake_create(spdinv, period, 0);
}

int periodic_wake_create_exist(spdid_t spdinv, unsigned int period)
{
	return __periodic_wake_create(spdinv, period, 1);
}

int periodic_wake_remove(spdid_t spdinv, unsigned short int tid)
{
	spdid_t spdid = cos_spd_id();
	struct thread_event *te;

	TAKE(spdid);
	te = te_pget(tid);
	if (NULL == te) BUG();
	if (!(te->flags & TE_PERIODIC)) goto err;
		
	assert(!EMPTY_LIST(te, next, prev));
	REM_LIST(te, next, prev);
	te->flags = 0;
	
	RELEASE(spdid);

	return 0;
err:
	RELEASE(spdid);
	return -1;
}

int periodic_wake_wait(spdid_t spdinv)
{
	spdid_t spdid = cos_spd_id();
	struct thread_event *te;
	u16_t tid = cos_get_thd_id();
	long long t;

	printc("thd %d calling period_wake_wait\n", cos_get_thd_id());

	WAIT_FAULT();

	TAKE(spdid);

	// SWIFI thread shoulod not wait for fault, it is injecing fault!!
	/* if (cos_get_thd_id() != 11) WAIT_FAULT(); */


	te = te_pget(tid);
	if (NULL == te) BUG();
	if (!(te->flags & TE_PERIODIC)) goto err;

	/* volatile unsigned long long wait_fault = 0; */
	/* while (wait_fault++ < 10000000); */
		
	assert(!EMPTY_LIST(te, next, prev));

	rdtscll(t);

#if (RECOVERY_ENABLE == 1) && defined(TEST_PTE_WAIT_BEFORE)
	/* test_num++; */ 
	if (spdinv == 17 && cos_get_thd_id() == 13 && test_num++ > 10) {
		printc("trigger fault in periodic_wake_wait before: thd %d spd %d\n", 
		       cos_get_thd_id(), spdid);
		assert(0);
	}
#endif

	if (te->missed) {	/* we're late */
		long long diff;
		if (te->miss_samples == 0){
			te->miss_samples = 1;
			te->samples = 1;
		}

		assert(te->completion);

		diff = (t - te->completion);
		te->lateness_tot += diff;
		//te->samples++;
		te->miss_lateness_tot += diff;
		//te->miss_samples++;
		
		te->completion = 0;
		te->missed = 0;
	} else {		/* on time! */
		te->completion = t;
	}
	if (te->need_restart > 0) {
		te->need_restart--;
		RELEASE(spdid);
		return 0;
	}
	te->flags |= TE_BLOCKED;
	RELEASE(spdid);

	// Jiguo: change to use event	
	long wait_ret;
redo:
	wait_ret = evt_wait(cos_spd_id(), te->evt);
	/* if return from the fault and the time is not expired, keep waiting */
	if (unlikely(wait_ret < 0 && !EMPTY_LIST(te, next, prev))) {
		/* printc("periodic_wake_wait: thd %d calls evt_wait again\n", cos_get_thd_id()); */
		goto redo;
	}

	/* if (!tmp) assert(0); */
	/* if (-1 == sched_block(spdid, 0)) { */
	/* 	prints("fprr: sched block failed in timed_event_periodic_wait.");	} */

	/* printc("leaving the periodic wake wait\n"); */

	WAIT_FAULT();
	
#if (RECOVERY_ENABLE == 1) && defined(TEST_PTE_WAIT_AFTER)
	/* test_num++; */
	/* /\* printc("in periodic_wake_wait: thd %d spd %d, test_num %d\n", *\/ */
	/* /\*        cos_get_thd_id(), spdinv, test_num); *\/ */
	/* if (spdinv == 16 && cos_get_thd_id() == 13 && test_num >= 2) { */
	if (spdinv == 17 && cos_get_thd_id() == 13 && test_num++ > 10) {
		printc("trigger fault in periodic_wake_wait after: thd %d spd %d\n", 
		       cos_get_thd_id(), spdid);
		assert(0);
	}
#endif

	/* printc("thd %d returns from period_wake_wait\n", cos_get_thd_id()); */

	return 0;
err:
	RELEASE(spdid);
	return -1;
}

static void start_timer_thread(int again)
{
	// Jiguo: use alignment here. Also set first to be 0 to ensure only one timer thd

	// align the following instructions
	// change this to __atrribute__((aligned(512))) later
	/* __asm__ volatile(".balign 512"); */
	
	spdid_t spdid = cos_spd_id();
	unsigned int tick_freq;

	/* printc("start timer thread %d (Kevinandy)\n", cos_get_thd_id()); */
	sched_timeout_thd(spdid);
	tick_freq = sched_tick_freq();
	assert(tick_freq == 100);
	ticks = sched_timestamp();
	/* currently timeouts are expressed in ticks, so we don't need this */
//	usec_per_tick = USEC_PER_SEC/tick_freq;
	cyc_per_tick = sched_cyc_per_tick();
	//	printc("cyc_per_tick = %lld\n", cyc_per_tick);

	if (likely(!again)) {
		/* When the system boots, we have no pending waits */
		assert(EMPTY_LIST(&events, next, prev));
		printc("start timer thread %d (Kevinandy) is blocking...\n", cos_get_thd_id());
		sched_block(spdid, 0);
	} // otherwise, this is the re-execution in home spd. Do not block -- Jiguo

	/* Wait for events, then act on expired events.  Loop. */
	while (1) {
		printc("timed_evt: timer thread %d (test_num %d)\n", 
		       cos_get_thd_id(), test_num);
#if (RECOVERY_ENABLE == 1) && defined(TEST_PTE_TIMER_THD_BEFORE)
		if (test_num++ > 10) {
			printc("trigger fault in timer before: thd %d spd %d\n", 
			       cos_get_thd_id(), spdid);
			assert(0);
		}
#endif
		event_time_t next_wakeup;
		cos_mpd_update(); /* update mpd config given this
				   * thread is now in this component
				   * (no dependency if we are in the
				   * same protection domain as the
				   * scheduler) */
		ticks = sched_timestamp();
		if (sched_component_take(spdid)) {
			prints("fprr: scheduler lock failed!!!");
			BUG();
		}

		event_expiration(ticks);
		next_wakeup = next_event_time();

		/* Are there no pending events??? */
		if (TIMER_NO_EVENTS == next_wakeup) {
			if (sched_component_release(spdid)) {
				prints("fprr: scheduler lock release failed!!!");
				BUG();
			}
			sched_block(spdid, 0);
		} else {
			unsigned int wakeup;
#ifdef LINUX_HIGHEST_PRIORITY
			//gap assert(next_wakeup > ticks);
#endif
			/* printc("next_wakeup %d ticks %d\n", next_wakeup, ticks); */
			/* Jiguo: not sure why this failed even when next_wakeup > ticks */
			assert(next_wakeup > ticks);
			wakeup = (unsigned int)(next_wakeup - ticks);
			if (sched_component_release(spdid)) {
				prints("fprr: scheduler lock release failed!!!");
				BUG();
			}

			sched_timeout(spdid, wakeup);
			
#if (RECOVERY_ENABLE == 1) && defined(TEST_PTE_TIMER_THD_AFTER)
			if (test_num++ > 10) {
				printc("trigger fault in timer after: thd %d spd %d\n", 
				       cos_get_thd_id(), spdid);
				assert(0);
			}
#endif
		}
	}
}

extern vaddr_t mman_reflect(spdid_t spd, int src_spd, int cnt);
extern int mman_release_page(spdid_t spd, vaddr_t addr, int flags); 

static void
rd_reflection()
{
	int count_obj = 0; // reflected objects
	int dest_spd = cos_spd_id();
	
	/* // remove the mapped page for mailbox spd */
	/* vaddr_t addr; */
	/* count_obj = mman_reflect(cos_spd_id(), dest_spd, 1); */
	/* /\* printc("pte relfects on mmgr: %d objs (thd %d)\n", count_obj, cos_get_thd_id()); *\/ */
	/* while (count_obj--) { */
	/* 	addr = mman_reflect(cos_spd_id(), dest_spd, 0); */
	/* 	/\* printc("evt mman_release: %p addr\n", (void *)addr); *\/ */
	/* 	mman_release_page(cos_spd_id(), addr, dest_spd); */
	/* } */

	/* sched_reflection(cos_spd_id()); */
	/* int wake_thd; */
	/* count_obj = sched_reflect(cos_spd_id(), dest_spd, 1); */
	/* /\* printc("pte relfects on sched: %d objs\n", count_obj); *\/ */
	/* while (count_obj--) { */
	/* 	wake_thd = sched_reflect(cos_spd_id(), dest_spd, 0); */
	/* 	/\* printc("thread %d wake_thd %d\n", cos_get_thd_id(), wake_thd); *\/ */
	/* 	sched_wakeup(cos_spd_id(), wake_thd); */
	/* } */
	// to reflect all threads blocked from evt component, such as evt_wait
	/* printc("pte reflects on evt_trigger_all (thd %d)\n\n", cos_get_thd_id()); */
	/* evt_trigger_all(cos_spd_id());  // for now, only pte and mailbox use this */

	sched_client_fault_notification(cos_spd_id());	
	evt_client_fault_notification(cos_spd_id());

	/* evt_reflection(cos_spd_id()); */
		
	/* printc("\nreflection done!!!\n\n"); */
	return;
}

static int init_first = 1;

void cos_init()
{
	union sched_param sp;

	if (init_first) {
		init_first = 0;
		INIT_LIST(&events, next, prev);
		events.thread_id = 0;
		INIT_LIST(&periodic, next, prev);
		periodic.thread_id = 0;

		cos_vect_init_static(&thd_evts);
		cos_vect_init_static(&thd_periodic);

		if (unlikely(cos_fault_cntl(COS_CAP_REFLECT_UPDATE, cos_spd_id(), 0))) {
			printc("need do reflection now!!!!\n");
			rd_reflection();
		} else {
			sp.c.type = SCHEDP_PRIO;
			sp.c.value = 3;
			if (cos_thd_create(start_timer_thread, NULL, sp.v, 0, 0) <= 0) BUG();
			printc("after timed_event component creates a new timer thread.\n");
		}

	}/*  else { */
	/* 	printc("timed_event component received too many bootstrap threads."); */
	/* } */
}

#ifdef EVT_C3
void events_replay_all();
#endif

void cos_upcall_fn(upcall_type_t t, void *arg1, void *arg2, void *arg3)
{
	/* printc("upcall type %d, core %ld, thd %d, args %p %p %p\n", */
	/*        t, cos_cpuid(), cos_get_thd_id(), arg1, arg2, arg3); */
	switch (t) {
	case COS_UPCALL_THD_CREATE:
	{
		printc("time_event: upcall to call cos_init (thd %d, spd %ld)\n",
		       cos_get_thd_id(), cos_spd_id());
		if (!arg1) cos_init();
		else start_timer_thread(0);  // Jiguo: no idea....thread can not find fn?
		break;
	}
	case COS_UPCALL_RECEVT:
		/* printc("time_event: upcall to recover the event (thd %d, spd %ld)\n", */
		/*        cos_get_thd_id(), cos_spd_id()); */
#ifdef EVT_C3
		events_replay_all();
#endif
		break;
	case COS_UPCALL_HOMEAGAIN:
		printc("time_event: reset execution in home spd (thd %d, spd %ld)\n",
		       cos_get_thd_id(), cos_spd_id());
		if (init_first) cos_init();
		start_timer_thread(1);   // restart execution timer thread
		assert(0);
		break;
	case COS_UPCALL_SWIFI_BEFORE:   // prepare for swifi
	{
		swifi_ready = 1; // now other thread can spin for inject fault
		break;
	}
	case COS_UPCALL_SWIFI_AFTER:   // allow other thread to proceed 
	{
		swifi_ready = 0; // now other thread can continue
		break;
	}
	default:
		return;
	}
	return;
}
